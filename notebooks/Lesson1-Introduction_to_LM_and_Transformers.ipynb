{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Lesson 1: Introduction to Language Models and Transformers\n",
       "\n",
       "Welcome to Lesson 1 of the **MiniLlama2-Tutorial**! In this lesson, we'll explore what language models are, their evolution, and the transformer architecture, which is the backbone of models like Llama 2.\n",
       "\n",
       "## Objectives\n",
       "- Understand what language models are and their applications.\n",
       "- Learn about the transformer architecture and its components.\n",
       "- Get an overview of Llama 2 and why we're building a smaller version.\n",
       "\n",
       "## What Are Language Models?\n",
       "\n",
       "Language models predict the next word or character in a sequence, used in text generation, chatbots, and translation. They evolved from n-gram models to neural networks, with transformers being the current state-of-the-art.\n",
       "\n",
       "## Transformer Architecture\n",
       "\n",
       "Transformers, introduced in the paper \"Attention Is All You Need\" ([Attention Is All You Need](https://arxiv.org/abs/1706.03762)), rely on attention mechanisms to process input sequences. Key components include:\n",
       "- Self-attention: Allows the model to focus on relevant parts of the input.\n",
       "- Positional encoding: Adds information about word positions.\n",
       "- Multi-head attention: Captures diverse representations.\n",
       "\n",
       "## Llama 2 Overview\n",
       "\n",
       "Llama 2, developed by Meta AI, has sizes from 7B to 70B parameters ([Llama 2 on Hugging Face](https://huggingface.co/meta-llama)). We're building a smaller version for learning, given computational constraints.\n",
       "\n",
       "## Exercises\n",
       "\n",
       "1. Read the Llama 2 research paper ([Llama 2 Research Paper](https://arxiv.org/abs/2307.09288)) and answer: What is the role of attention in transformers?\n",
       "2. Explain in your own words why a smaller model is suitable for this tutorial."
      ]
     }
    ],
    "metadata": {
     "language_info": {
      "name": "python"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }